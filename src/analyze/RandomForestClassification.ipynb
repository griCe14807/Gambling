{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このノートでやった（できる）こと\n",
    "### Logistic regressionを用いて、目的変数の確率を算出し、算出した値を元に様々な掛け方をした場合の回収率を計算\n",
    "\n",
    "#### 計算に用いた特徴量\n",
    "- 各レーサーのクラス\n",
    "- 各レーサーの各枠における平均スタートタイム\n",
    "- 各レーサーの連帯率\n",
    "- 展示タイム\n",
    "- 各モーターの2連率\n",
    "- 各モーターの3連率\n",
    "- 各ボートの2連率\n",
    "- 各ボートの3連率\n",
    "\n",
    "#### 目的変数\n",
    "- 1枠: 1着になる (1) or ならない (0)\n",
    "- 2-6枠: 3着以内にはいる (1) or 入らない (0)\n",
    "\n",
    "\n",
    "### 結果\n",
    "#### RandomForest classification結果\n",
    "- XXX\n",
    "- XXX\n",
    "#### bet結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインポート\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import termcolor\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(current_dir, '../conf/'))\n",
    "sys.path.append(os.path.join(current_dir, '../crawl/'))\n",
    "sys.path.append(os.path.join(current_dir, '../data_preparing/'))\n",
    "sys.path.append(os.path.join(current_dir, 'analyzer_conf/'))\n",
    "\n",
    "# my module\n",
    "import loader\n",
    "import boatrace_crawler_conf\n",
    "import analyzer_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02217013\\Documents\\GitHub\\boatrace\\src\\analyze\\../data_preparing\\loader.py:357: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  race_results_supplementary_df = pd.concat(race_results_supplementary_df_list)\n"
     ]
    }
   ],
   "source": [
    "# 過去のレース結果をdfとして取得\n",
    "the_merged_df = loader.main()\n",
    "# dfをソート\n",
    "the_merged_df = the_merged_df.sort_values([\"date\", \"venue\", \"raceNumber\"])\n",
    "# print(the_merged_df[\"CS_frame_1_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfを期間で区切って小さくして使いたい時\n",
    "from_dt = datetime(2019, 1, 1)\n",
    "to_dt = datetime(2019, 3, 1)\n",
    "\n",
    "the_merged_df = the_merged_df[(the_merged_df[\"date\"] >= from_dt) & (the_merged_df[\"date\"] <= to_dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  method=method)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\02217013\\Documents\\GitHub\\boatrace\\src\\analyze\\analyzer_conf.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  for_analysis_df.loc[for_analysis_df[column_name] != 1, column_name] = 0\n",
      "C:\\Users\\02217013\\Documents\\GitHub\\boatrace\\src\\analyze\\analyzer_conf.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  for_analysis_df.loc[for_analysis_df[column_name] < 3.5, column_name] = 1\n",
      "C:\\Users\\02217013\\Documents\\GitHub\\boatrace\\src\\analyze\\analyzer_conf.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  for_analysis_df.loc[for_analysis_df[column_name] > 3.5, column_name] = 0\n"
     ]
    }
   ],
   "source": [
    "# Random forest regressionを利用した学習\n",
    "\n",
    "def make_df_for_analyze(merged_df, fv_list, column_list_label, odds_list):\n",
    "    \"\"\"\n",
    "    parameters\n",
    "        fv_list: dfのうち、特徴量として用いるカラム名のリスト\n",
    "        column_list_label: dfのうち、labelとして用いるカラム名のリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    # 特徴量のdfを作成\n",
    "    fv_df = merged_df[fv_list]\n",
    "    \n",
    "    # クラスカラムを，A1 =0, A2 = 1のように数字に変換する\n",
    "    class_dict = {\"A1\": 0, \"A2\":1, \"B1\": 2, \"B2\": 3}\n",
    "    for key, value in class_dict.items():\n",
    "        fv_df.replace(key, value, inplace = True)\n",
    "\n",
    "    # 会場名をbooleanに変換\n",
    "    venue_df = pd.get_dummies(fv_df[\"venue\"])\n",
    "    \n",
    "    # fv_dfの方の会場の列を削除\n",
    "    fv_df = fv_df.drop(\"venue\", axis=1)\n",
    "    \n",
    "    # 会場名がbooleanになったfv_dfの作成\n",
    "    fv_df = pd.concat([fv_df, venue_df], axis=1)\n",
    "    \n",
    "    # なぜかdtypeがstrになっちゃうのでfloatに戻す\n",
    "    fv_df = fv_df.astype(float)\n",
    "    \n",
    "    # labelのdfを作成\n",
    "    label_df = merged_df[column_list_label]\n",
    "    \n",
    "    # ラベルをbooleanに変換\n",
    "    label_df = analyzer_conf.make_label_boolean_ver1(label_df, column_list_label)\n",
    "    \n",
    "    \"\"\"\n",
    "    # 特徴量を標準化\n",
    "    fv_label_df = analyzer_conf.standerdize_feature_values(\n",
    "        fv_label_df, column_list_label)\n",
    "    \"\"\"\n",
    "    \n",
    "    # オッズのdfを作成\n",
    "    odds_df = merged_df[odds_list]\n",
    "    \n",
    "    # 解析用dfを作成\n",
    "    fv_label_odds_df = pd.concat([fv_df, label_df, odds_df], axis=1)\n",
    "    # nanを含む行を削除\n",
    "    fv_label_odds_df = fv_label_odds_df.dropna()\n",
    "    \n",
    "    # oddsはないバージョンのdf\n",
    "    fv_label_df = pd.concat([fv_df, label_df], axis=1)\n",
    "    # nanを含む行を削除\n",
    "    fv_label_df = fv_label_df.dropna()\n",
    "    \n",
    "    \"\"\"\n",
    "    print(len(fv_df), len(label_df), len(odds_df))\n",
    "    print(\"解析用dfの行数は.{0}\".format(len(fv_label_df)))\n",
    "    print(fv_label_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    return fv_label_df, fv_label_odds_df\n",
    "\n",
    "\n",
    "def separate_train_test_dataset(for_analysis_df, train_data_ratio):\n",
    "       \n",
    "    # 解析用df（特徴量+label）を、学習用データとテストデータのarrayに分ける\n",
    "    train_size = int(len(for_analysis_df) * train_data_ratio)\n",
    "    train_data = for_analysis_df[:train_size].values\n",
    "    test_data = for_analysis_df[train_size:].values\n",
    "    \n",
    "    return train_data, test_data, train_size\n",
    "\n",
    "    \n",
    "def learn_logistic_regression(train_data, column_list_label, num_estimators, max_depth, max_features):\n",
    "    \n",
    "    \"\"\"\n",
    "    1枠が1着になるかどうか？2枠以降に関しては3着以内に入るかどうか？を scikit-lernのlogistic regressionを用いて学習する。\n",
    "    複数のラベルをリストとして入力することが可能で、戻り値はそれぞれのlabelに対して学習を行なった結果のモデルを各要素にもつリスト\n",
    "    \n",
    "    return\n",
    "        clf_list: 各ラベルについて学習したモデルのlist\n",
    "    \n",
    "    TODO\n",
    "        ラベルの作成方法などもinput parameterとして指定できた方がいい。\n",
    "        むしろregressionの方法もinputにして超汎用的な関数を外側に作るか？\n",
    "    \n",
    "    \"\"\"\n",
    "    # ラベルとしてもちいる部分の数。labelと特徴量を分ける際に使用、\n",
    "    num_labels = len(column_list_label)\n",
    "    \n",
    "    # 特徴量部分のarray\n",
    "    train_x = train_data[:, :-num_labels]\n",
    "\n",
    "    # 分類を行なった結果得られるオブジェクトをリストに格納\n",
    "    clf_list  = []\n",
    "\n",
    "    for i, column_label in enumerate(column_list_label):\n",
    "        # ラベルを指定\n",
    "        train_t = train_data[:, - num_labels + i]\n",
    "\n",
    "        # Random Forest Classification\n",
    "        clf = RFC(n_estimators=num_estimators, max_depth=max_depth, max_features=max_features, n_jobs=-1)\n",
    "        clf.fit(train_x, train_t)\n",
    "\n",
    "        clf_list.append(clf)\n",
    "    \n",
    "    return clf_list, num_labels\n",
    "\n",
    "\n",
    "# ----------input-------------\n",
    "# 解析に使う特徴量カラム\n",
    "fv_list = []\n",
    "\n",
    "# 開催地\n",
    "fv_list.append(\"venue\")    \n",
    "\n",
    "for i in range(1, 7):\n",
    "    # 各枠のレーサーのクラス\n",
    "    fv_list.append(\"class_{0}\".format(i))\n",
    "    # 各レーサーの該当枠における平均ST\n",
    "    fv_list.append(\"aveST_frame{0}\".format(i))\n",
    "    # 各レーサーの該当枠における連帯率\n",
    "    fv_list.append(\"placeRate_frame{0}\".format(i))\n",
    "    \n",
    "    # 勝率・二連率・三連率（全国）\n",
    "    fv_list.append(\"win_rate_national_{0}\".format(i))\n",
    "    fv_list.append(\"place2Ratio_national_{0}\".format(i))\n",
    "    fv_list.append(\"place3Ratio_national_{0}\".format(i))\n",
    "    \n",
    "    # 勝率・二連率・三連率（当地）\n",
    "    fv_list.append(\"win_rate_local_{0}\".format(i))\n",
    "    fv_list.append(\"place2Ratio_local_{0}\".format(i))\n",
    "    fv_list.append(\"place3Ratio_local_{0}\".format(i))\n",
    "    \n",
    "    # 展示タイム\n",
    "    fv_list.append(\"exhibitionTime_{0}\".format(i))\n",
    "    \n",
    "    # 各モーターの2連率, 3連率\n",
    "    fv_list.append(\"motor_place2Ratio_{0}\".format(i))\n",
    "    fv_list.append(\"motor_place3Ratio_{0}\".format(i))\n",
    "    \n",
    "    # ボートの2連率、3連率\n",
    "    fv_list.append(\"boat_place2Ratio_{0}\".format(i))\n",
    "    fv_list.append(\"boat_place3Ratio_{0}\".format(i))\n",
    "    \n",
    "    # 展示競争の進入コース\n",
    "    fv_list.append(\"exhibition_cource_{0}\".format(i))\n",
    "    \n",
    "    \n",
    "    # 直前のレースの成績\n",
    "    # for j in range(1, 12):\n",
    "        # fv_list.append(\"CS_frame_{0}_{1}\".format(i, j))\n",
    "        # fv_list.append(\"CS_rank_{0}_{1}\".format(i, j))\n",
    "\n",
    "# 解析に使うラベルカラム: 1枠が1着になるか, 2枠以降は3着以降に入るかどうか？を予測\n",
    "column_list_label = [\"rank_{0}\".format(i) for i in range(1,7)]\n",
    "\n",
    "# 回収率計算に使用するオッズラベルのリスト\n",
    "odds_list =  [\"win\", \"winOdds\", \n",
    "             \"place_1\", \"placeOdds_1\",\n",
    "             \"place_2\", \"placeOdds_2\",\n",
    "             \"exacta\", \"exactaOdds\",\n",
    "             \"quinella\", \"quinellaOdds\",\n",
    "             \"wide_1\", \"wideOdds_1\", \n",
    "             \"wide_2\", \"wideOdds_2\",\n",
    "             \"wide_3\", \"wideOdds_3\",\n",
    "             \"trifecta\", \"trifectaOdds\",\n",
    "             \"trio\", \"trioOdds\"]\n",
    "\n",
    "# データのうち、教師データとして使う割合（残りをテストデータとして用いる）\n",
    "train_data_ratio = 0.8\n",
    "# random forestの木の本数\n",
    "num_estimators = 100\n",
    "# 探索木の最大深さ\n",
    "max_depth = 8\n",
    "#  サンプリングする特徴量の数\n",
    "max_features = None\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# main\n",
    "\n",
    "fv_label_df, fv_label_odds_df = make_df_for_analyze(the_merged_df, fv_list, column_list_label, odds_list)\n",
    "train_data, test_data, train_size = separate_train_test_dataset(fv_label_df, train_data_ratio)\n",
    "clf_list, num_labels = learn_logistic_regression(train_data, column_list_label, num_estimators, max_depth, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class_1  aveST_frame1  placeRate_frame1  win_rate_national_1  \\\n",
      "96         0.0          18.0             853.0                 7.14   \n",
      "97         2.0          16.0             545.0                 5.51   \n",
      "98         1.0          13.0             880.0                 6.29   \n",
      "99         2.0          18.0             273.0                 3.58   \n",
      "100        0.0          15.0             923.0                 6.50   \n",
      "101        2.0          14.0             417.0                 4.46   \n",
      "102        1.0          15.0             682.0                 6.30   \n",
      "103        0.0          16.0             840.0                 5.91   \n",
      "104        0.0          13.0             885.0                 7.13   \n",
      "105        0.0          14.0             848.0                 7.80   \n",
      "36         0.0          15.0             739.0                 6.86   \n",
      "37         2.0          19.0             538.0                 5.05   \n",
      "38         2.0          35.0             250.0                 3.24   \n",
      "39         1.0          18.0             727.0                 5.06   \n",
      "40         1.0          16.0             941.0                 5.46   \n",
      "41         2.0          17.0             444.0                 3.90   \n",
      "42         1.0          16.0             900.0                 5.75   \n",
      "43         0.0          11.0             970.0                 7.53   \n",
      "44         0.0          14.0             875.0                 7.06   \n",
      "45         0.0          14.0             943.0                 6.70   \n",
      "46         0.0          13.0             921.0                 6.64   \n",
      "47         2.0          21.0             571.0                 4.85   \n",
      "72         1.0          13.0             892.0                 6.56   \n",
      "73         2.0          16.0             714.0                 5.16   \n",
      "74         2.0          19.0             538.0                 4.37   \n",
      "75         2.0          15.0             600.0                 3.44   \n",
      "76         1.0          18.0             593.0                 5.44   \n",
      "77         2.0          14.0             500.0                 4.62   \n",
      "78         2.0          12.0             833.0                 4.68   \n",
      "79         1.0          13.0             880.0                 6.90   \n",
      "...        ...           ...               ...                  ...   \n",
      "40088      2.0          15.0             538.0                 4.98   \n",
      "40089      0.0          16.0             897.0                 6.62   \n",
      "40090      3.0          18.0             500.0                 3.41   \n",
      "40091      0.0          15.0             739.0                 7.22   \n",
      "40092      0.0          16.0             941.0                 7.57   \n",
      "40093      3.0           0.0               0.0                 7.08   \n",
      "40094      2.0          20.0             250.0                 3.43   \n",
      "40095      2.0          19.0             429.0                 4.46   \n",
      "40096      2.0          17.0             400.0                 4.63   \n",
      "40097      2.0          16.0             700.0                 4.42   \n",
      "40098      1.0          12.0             773.0                 6.56   \n",
      "40099      1.0          17.0             808.0                 6.09   \n",
      "40100      1.0          14.0             880.0                 5.67   \n",
      "40101      1.0          16.0             913.0                 5.21   \n",
      "40102      2.0          17.0             231.0                 4.72   \n",
      "40103      3.0          11.0             913.0                 4.50   \n",
      "40104      0.0          16.0             724.0                 6.47   \n",
      "40105      1.0          18.0             867.0                 5.65   \n",
      "40106      0.0          15.0             850.0                 7.70   \n",
      "40107      0.0          13.0             903.0                 7.30   \n",
      "40108      0.0          17.0             793.0                 7.36   \n",
      "40109      0.0          11.0             829.0                 7.12   \n",
      "40110      0.0          14.0             828.0                 7.64   \n",
      "40111      0.0          13.0             906.0                 7.85   \n",
      "40112      0.0          12.0            1000.0                 7.91   \n",
      "40113      0.0          14.0             857.0                 6.90   \n",
      "40114      0.0          14.0             882.0                 7.64   \n",
      "40115      0.0          14.0             975.0                 7.34   \n",
      "40116      0.0          11.0             906.0                 7.37   \n",
      "40117      0.0          12.0             897.0                 7.59   \n",
      "\n",
      "       place2Ratio_national_1  place3Ratio_national_1  win_rate_local_1  \\\n",
      "96                      55.40                   72.66              5.84   \n",
      "97                      38.71                   56.99              3.81   \n",
      "98                      45.97                   61.29              6.96   \n",
      "99                      13.21                   30.19              2.44   \n",
      "100                     47.33                   69.47              6.19   \n",
      "101                     25.00                   35.71              3.09   \n",
      "102                     41.88                   64.10              5.90   \n",
      "103                     40.00                   66.15              4.94   \n",
      "104                     44.26                   61.48              7.74   \n",
      "105                     56.83                   73.38              8.56   \n",
      "36                      47.29                   74.42              6.57   \n",
      "37                      32.10                   45.68              4.89   \n",
      "38                       8.16                   24.49              3.30   \n",
      "39                      31.75                   51.59              4.83   \n",
      "40                      32.86                   51.43              5.53   \n",
      "41                      17.60                   30.40              1.85   \n",
      "42                      37.61                   58.97              6.73   \n",
      "43                      51.89                   69.81              8.69   \n",
      "44                      51.30                   71.30              7.53   \n",
      "45                      46.75                   68.83              6.94   \n",
      "46                      44.63                   68.60              7.24   \n",
      "47                      32.26                   45.16              2.83   \n",
      "72                      51.50                   68.86              5.93   \n",
      "73                      29.52                   47.62              5.49   \n",
      "74                      16.13                   41.94              4.40   \n",
      "75                      13.24                   22.06              4.07   \n",
      "76                      38.39                   51.79              6.18   \n",
      "77                      23.40                   41.49              5.10   \n",
      "78                      25.25                   42.42              5.51   \n",
      "79                      48.12                   69.92              6.75   \n",
      "...                       ...                     ...               ...   \n",
      "40088                   30.00                   50.00              2.28   \n",
      "40089                   48.15                   66.67              8.00   \n",
      "40090                   14.63                   24.39              0.00   \n",
      "40091                   50.00                   68.25              6.10   \n",
      "40092                   62.20                   72.44              7.64   \n",
      "40093                   60.00                   72.22              0.00   \n",
      "40094                   16.67                   23.96              2.65   \n",
      "40095                   27.63                   38.16              4.86   \n",
      "40096                   23.81                   44.05              3.61   \n",
      "40097                   19.35                   38.71              5.37   \n",
      "40098                   46.61                   64.41              6.65   \n",
      "40099                   44.83                   65.52              5.50   \n",
      "40100                   39.66                   57.76              6.24   \n",
      "40101                   29.63                   46.30              5.36   \n",
      "40102                   22.34                   44.68              4.58   \n",
      "40103                   25.00                   37.50              7.48   \n",
      "40104                   52.04                   63.27              6.35   \n",
      "40105                   37.62                   58.42              5.42   \n",
      "40106                   60.14                   79.71              7.78   \n",
      "40107                   48.68                   71.05              9.00   \n",
      "40108                   56.93                   78.10              7.37   \n",
      "40109                   49.62                   69.47              7.89   \n",
      "40110                   62.39                   74.36              6.74   \n",
      "40111                   59.20                   72.80              8.72   \n",
      "40112                   57.63                   76.27              7.38   \n",
      "40113                   50.74                   67.65              6.61   \n",
      "40114                   46.96                   73.04              6.63   \n",
      "40115                   52.86                   66.43              6.20   \n",
      "40116                   60.51                   75.16              7.01   \n",
      "40117                   57.38                   72.13              7.78   \n",
      "\n",
      "       place2Ratio_local_1  place3Ratio_local_1  exhibitionTime_1  ...  芦　屋  \\\n",
      "96                   38.27                58.02              6.66  ...  0.0   \n",
      "97                   23.08                35.16              6.64  ...  0.0   \n",
      "98                   55.28                72.05              6.80  ...  0.0   \n",
      "99                   11.11                11.11              6.68  ...  0.0   \n",
      "100                  45.61                65.79              6.86  ...  0.0   \n",
      "101                  11.32                18.87              6.74  ...  0.0   \n",
      "102                  40.11                58.76              6.70  ...  0.0   \n",
      "103                  29.03                41.94              6.70  ...  0.0   \n",
      "104                  64.89                78.72              6.74  ...  0.0   \n",
      "105                  78.20                88.72              6.69  ...  0.0   \n",
      "36                   49.07                74.07              6.65  ...  0.0   \n",
      "37                   25.00                38.64              6.66  ...  0.0   \n",
      "38                    8.11                32.43              6.69  ...  0.0   \n",
      "39                   27.78                50.00              6.69  ...  0.0   \n",
      "40                   40.00                53.33              6.69  ...  0.0   \n",
      "41                    0.00                 7.69              6.60  ...  0.0   \n",
      "42                   40.91                72.73              6.69  ...  0.0   \n",
      "43                   72.31                86.15              6.72  ...  0.0   \n",
      "44                   64.75                79.51              6.72  ...  0.0   \n",
      "45                   53.25                71.43              6.66  ...  0.0   \n",
      "46                   54.69                74.22              6.79  ...  0.0   \n",
      "47                    8.70                13.04              6.73  ...  0.0   \n",
      "72                   44.13                61.50              6.79  ...  0.0   \n",
      "73                   35.85                52.83              6.78  ...  0.0   \n",
      "74                   18.55                37.90              6.79  ...  0.0   \n",
      "75                   22.00                30.00              6.69  ...  0.0   \n",
      "76                   44.58                63.25              6.65  ...  0.0   \n",
      "77                   30.77                53.85              6.72  ...  0.0   \n",
      "78                   36.29                54.84              6.70  ...  0.0   \n",
      "79                   49.12                73.68              6.74  ...  0.0   \n",
      "...                    ...                  ...               ...  ...  ...   \n",
      "40088                 0.00                 8.00              6.78  ...  1.0   \n",
      "40089                61.11                83.33              6.75  ...  1.0   \n",
      "40090                 0.00                 0.00              6.84  ...  1.0   \n",
      "40091                44.59                61.49              6.78  ...  1.0   \n",
      "40092                62.50                73.21              6.74  ...  1.0   \n",
      "40093                 0.00                 0.00              6.74  ...  1.0   \n",
      "40094                 9.30                16.28              6.88  ...  0.0   \n",
      "40095                31.82                45.45              6.95  ...  0.0   \n",
      "40096                 8.70                34.78              6.87  ...  0.0   \n",
      "40097                33.33                56.67              6.94  ...  0.0   \n",
      "40098                41.18                52.94              6.82  ...  0.0   \n",
      "40099                22.22                61.11              6.87  ...  0.0   \n",
      "40100                47.62                66.67              6.80  ...  0.0   \n",
      "40101                33.33                45.45              6.82  ...  0.0   \n",
      "40102                20.83                45.83              6.79  ...  0.0   \n",
      "40103                68.04                75.26              6.80  ...  0.0   \n",
      "40104                52.13                63.83              6.82  ...  0.0   \n",
      "40105                30.30                57.58              6.87  ...  0.0   \n",
      "40106                67.57                75.68              6.79  ...  0.0   \n",
      "40107                62.50                75.00              6.76  ...  0.0   \n",
      "40108                50.00                76.32              6.75  ...  0.0   \n",
      "40109                62.96                77.78              6.76  ...  0.0   \n",
      "40110                45.16                58.06              6.74  ...  0.0   \n",
      "40111                64.00                84.00              6.76  ...  0.0   \n",
      "40112                56.25                62.50              6.75  ...  0.0   \n",
      "40113                42.11                76.32              6.78  ...  0.0   \n",
      "40114                42.86                51.43              6.70  ...  0.0   \n",
      "40115                20.00                50.00              6.66  ...  0.0   \n",
      "40116                52.38                69.64              6.73  ...  0.0   \n",
      "40117                63.35                76.40              6.73  ...  0.0   \n",
      "\n",
      "       若　松  蒲　郡  鳴　門  rank_1  rank_2  rank_3  rank_4  rank_5  rank_6  \n",
      "96     0.0  0.0  0.0       0       1       0       0       0       1  \n",
      "97     0.0  0.0  0.0       1       0       1       0       0       1  \n",
      "98     0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "99     0.0  0.0  0.0       1       1       1       0       0       0  \n",
      "100    0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "101    0.0  0.0  0.0       0       1       0       0       1       1  \n",
      "102    0.0  0.0  0.0       1       1       0       1       0       0  \n",
      "103    0.0  0.0  0.0       1       1       1       0       0       0  \n",
      "104    0.0  0.0  0.0       1       0       0       1       1       0  \n",
      "105    0.0  0.0  0.0       1       0       0       1       1       0  \n",
      "36     0.0  0.0  0.0       1       0       0       1       1       0  \n",
      "37     0.0  0.0  0.0       0       1       0       1       1       1  \n",
      "38     0.0  0.0  0.0       0       1       1       1       0       0  \n",
      "39     0.0  0.0  0.0       0       0       1       1       0       0  \n",
      "40     0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "41     0.0  0.0  0.0       0       1       1       0       0       0  \n",
      "42     0.0  0.0  0.0       0       0       1       1       0       0  \n",
      "43     0.0  0.0  0.0       1       1       1       0       0       0  \n",
      "44     0.0  0.0  0.0       1       0       1       0       0       1  \n",
      "45     0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "46     0.0  0.0  0.0       1       1       0       0       1       0  \n",
      "47     0.0  0.0  0.0       1       1       1       1       0       0  \n",
      "72     0.0  0.0  0.0       1       1       0       1       0       0  \n",
      "73     0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "74     0.0  0.0  0.0       0       1       0       1       0       0  \n",
      "75     0.0  0.0  0.0       1       1       0       1       0       0  \n",
      "76     0.0  0.0  0.0       0       0       1       1       0       1  \n",
      "77     0.0  0.0  0.0       0       1       1       0       1       0  \n",
      "78     0.0  0.0  0.0       0       1       0       1       0       0  \n",
      "79     0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "...    ...  ...  ...     ...     ...     ...     ...     ...     ...  \n",
      "40088  0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "40089  0.0  0.0  0.0       1       0       0       1       1       0  \n",
      "40090  0.0  0.0  0.0       0       1       0       0       0       1  \n",
      "40091  0.0  0.0  0.0       1       1       1       0       0       0  \n",
      "40092  0.0  0.0  0.0       1       1       1       0       0       0  \n",
      "40093  0.0  0.0  0.0       1       0       1       1       0       0  \n",
      "40094  1.0  0.0  0.0       1       1       1       0       0       0  \n",
      "40095  1.0  0.0  0.0       0       1       0       1       0       1  \n",
      "40096  1.0  0.0  0.0       0       1       1       1       0       0  \n",
      "40097  1.0  0.0  0.0       0       0       1       1       1       0  \n",
      "40098  1.0  0.0  0.0       1       1       0       1       0       0  \n",
      "40099  1.0  0.0  0.0       0       1       1       1       0       0  \n",
      "40100  1.0  0.0  0.0       1       0       0       1       1       0  \n",
      "40101  1.0  0.0  0.0       0       1       1       0       0       0  \n",
      "40102  1.0  0.0  0.0       1       1       1       0       0       0  \n",
      "40103  1.0  0.0  0.0       0       1       0       1       0       1  \n",
      "40104  1.0  0.0  0.0       1       1       1       0       0       0  \n",
      "40105  1.0  0.0  0.0       0       1       1       0       0       0  \n",
      "40106  0.0  0.0  1.0       1       0       1       0       1       0  \n",
      "40107  0.0  0.0  1.0       0       0       1       0       0       1  \n",
      "40108  0.0  0.0  1.0       1       1       0       1       0       0  \n",
      "40109  0.0  0.0  1.0       1       0       1       0       0       1  \n",
      "40110  0.0  0.0  1.0       0       0       0       1       1       0  \n",
      "40111  0.0  0.0  1.0       1       1       0       0       1       0  \n",
      "40112  0.0  0.0  1.0       0       0       1       0       1       1  \n",
      "40113  0.0  0.0  1.0       1       1       1       0       0       0  \n",
      "40114  0.0  0.0  1.0       0       1       1       0       0       0  \n",
      "40115  0.0  0.0  1.0       1       1       0       0       0       1  \n",
      "40116  0.0  0.0  1.0       1       1       1       1       0       0  \n",
      "40117  0.0  0.0  1.0       1       1       0       0       1       0  \n",
      "\n",
      "[23163 rows x 120 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fv_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class_1  aveST_frame1  placeRate_frame1  win_rate_national_1  \\\n",
      "96         0.0          18.0             853.0                 7.14   \n",
      "97         2.0          16.0             545.0                 5.51   \n",
      "98         1.0          13.0             880.0                 6.29   \n",
      "99         2.0          18.0             273.0                 3.58   \n",
      "100        0.0          15.0             923.0                 6.50   \n",
      "101        2.0          14.0             417.0                 4.46   \n",
      "102        1.0          15.0             682.0                 6.30   \n",
      "103        0.0          16.0             840.0                 5.91   \n",
      "104        0.0          13.0             885.0                 7.13   \n",
      "105        0.0          14.0             848.0                 7.80   \n",
      "36         0.0          15.0             739.0                 6.86   \n",
      "37         2.0          19.0             538.0                 5.05   \n",
      "38         2.0          35.0             250.0                 3.24   \n",
      "39         1.0          18.0             727.0                 5.06   \n",
      "40         1.0          16.0             941.0                 5.46   \n",
      "41         2.0          17.0             444.0                 3.90   \n",
      "42         1.0          16.0             900.0                 5.75   \n",
      "43         0.0          11.0             970.0                 7.53   \n",
      "44         0.0          14.0             875.0                 7.06   \n",
      "45         0.0          14.0             943.0                 6.70   \n",
      "46         0.0          13.0             921.0                 6.64   \n",
      "47         2.0          21.0             571.0                 4.85   \n",
      "72         1.0          13.0             892.0                 6.56   \n",
      "73         2.0          16.0             714.0                 5.16   \n",
      "74         2.0          19.0             538.0                 4.37   \n",
      "75         2.0          15.0             600.0                 3.44   \n",
      "76         1.0          18.0             593.0                 5.44   \n",
      "77         2.0          14.0             500.0                 4.62   \n",
      "78         2.0          12.0             833.0                 4.68   \n",
      "79         1.0          13.0             880.0                 6.90   \n",
      "...        ...           ...               ...                  ...   \n",
      "40088      2.0          15.0             538.0                 4.98   \n",
      "40089      0.0          16.0             897.0                 6.62   \n",
      "40090      3.0          18.0             500.0                 3.41   \n",
      "40091      0.0          15.0             739.0                 7.22   \n",
      "40092      0.0          16.0             941.0                 7.57   \n",
      "40093      3.0           0.0               0.0                 7.08   \n",
      "40094      2.0          20.0             250.0                 3.43   \n",
      "40095      2.0          19.0             429.0                 4.46   \n",
      "40096      2.0          17.0             400.0                 4.63   \n",
      "40097      2.0          16.0             700.0                 4.42   \n",
      "40098      1.0          12.0             773.0                 6.56   \n",
      "40099      1.0          17.0             808.0                 6.09   \n",
      "40100      1.0          14.0             880.0                 5.67   \n",
      "40101      1.0          16.0             913.0                 5.21   \n",
      "40102      2.0          17.0             231.0                 4.72   \n",
      "40103      3.0          11.0             913.0                 4.50   \n",
      "40104      0.0          16.0             724.0                 6.47   \n",
      "40105      1.0          18.0             867.0                 5.65   \n",
      "40106      0.0          15.0             850.0                 7.70   \n",
      "40107      0.0          13.0             903.0                 7.30   \n",
      "40108      0.0          17.0             793.0                 7.36   \n",
      "40109      0.0          11.0             829.0                 7.12   \n",
      "40110      0.0          14.0             828.0                 7.64   \n",
      "40111      0.0          13.0             906.0                 7.85   \n",
      "40112      0.0          12.0            1000.0                 7.91   \n",
      "40113      0.0          14.0             857.0                 6.90   \n",
      "40114      0.0          14.0             882.0                 7.64   \n",
      "40115      0.0          14.0             975.0                 7.34   \n",
      "40116      0.0          11.0             906.0                 7.37   \n",
      "40117      0.0          12.0             897.0                 7.59   \n",
      "\n",
      "       place2Ratio_national_1  place3Ratio_national_1  win_rate_local_1  \\\n",
      "96                      55.40                   72.66              5.84   \n",
      "97                      38.71                   56.99              3.81   \n",
      "98                      45.97                   61.29              6.96   \n",
      "99                      13.21                   30.19              2.44   \n",
      "100                     47.33                   69.47              6.19   \n",
      "101                     25.00                   35.71              3.09   \n",
      "102                     41.88                   64.10              5.90   \n",
      "103                     40.00                   66.15              4.94   \n",
      "104                     44.26                   61.48              7.74   \n",
      "105                     56.83                   73.38              8.56   \n",
      "36                      47.29                   74.42              6.57   \n",
      "37                      32.10                   45.68              4.89   \n",
      "38                       8.16                   24.49              3.30   \n",
      "39                      31.75                   51.59              4.83   \n",
      "40                      32.86                   51.43              5.53   \n",
      "41                      17.60                   30.40              1.85   \n",
      "42                      37.61                   58.97              6.73   \n",
      "43                      51.89                   69.81              8.69   \n",
      "44                      51.30                   71.30              7.53   \n",
      "45                      46.75                   68.83              6.94   \n",
      "46                      44.63                   68.60              7.24   \n",
      "47                      32.26                   45.16              2.83   \n",
      "72                      51.50                   68.86              5.93   \n",
      "73                      29.52                   47.62              5.49   \n",
      "74                      16.13                   41.94              4.40   \n",
      "75                      13.24                   22.06              4.07   \n",
      "76                      38.39                   51.79              6.18   \n",
      "77                      23.40                   41.49              5.10   \n",
      "78                      25.25                   42.42              5.51   \n",
      "79                      48.12                   69.92              6.75   \n",
      "...                       ...                     ...               ...   \n",
      "40088                   30.00                   50.00              2.28   \n",
      "40089                   48.15                   66.67              8.00   \n",
      "40090                   14.63                   24.39              0.00   \n",
      "40091                   50.00                   68.25              6.10   \n",
      "40092                   62.20                   72.44              7.64   \n",
      "40093                   60.00                   72.22              0.00   \n",
      "40094                   16.67                   23.96              2.65   \n",
      "40095                   27.63                   38.16              4.86   \n",
      "40096                   23.81                   44.05              3.61   \n",
      "40097                   19.35                   38.71              5.37   \n",
      "40098                   46.61                   64.41              6.65   \n",
      "40099                   44.83                   65.52              5.50   \n",
      "40100                   39.66                   57.76              6.24   \n",
      "40101                   29.63                   46.30              5.36   \n",
      "40102                   22.34                   44.68              4.58   \n",
      "40103                   25.00                   37.50              7.48   \n",
      "40104                   52.04                   63.27              6.35   \n",
      "40105                   37.62                   58.42              5.42   \n",
      "40106                   60.14                   79.71              7.78   \n",
      "40107                   48.68                   71.05              9.00   \n",
      "40108                   56.93                   78.10              7.37   \n",
      "40109                   49.62                   69.47              7.89   \n",
      "40110                   62.39                   74.36              6.74   \n",
      "40111                   59.20                   72.80              8.72   \n",
      "40112                   57.63                   76.27              7.38   \n",
      "40113                   50.74                   67.65              6.61   \n",
      "40114                   46.96                   73.04              6.63   \n",
      "40115                   52.86                   66.43              6.20   \n",
      "40116                   60.51                   75.16              7.01   \n",
      "40117                   57.38                   72.13              7.78   \n",
      "\n",
      "       place2Ratio_local_1  place3Ratio_local_1  exhibitionTime_1  ...  \\\n",
      "96                   38.27                58.02              6.66  ...   \n",
      "97                   23.08                35.16              6.64  ...   \n",
      "98                   55.28                72.05              6.80  ...   \n",
      "99                   11.11                11.11              6.68  ...   \n",
      "100                  45.61                65.79              6.86  ...   \n",
      "101                  11.32                18.87              6.74  ...   \n",
      "102                  40.11                58.76              6.70  ...   \n",
      "103                  29.03                41.94              6.70  ...   \n",
      "104                  64.89                78.72              6.74  ...   \n",
      "105                  78.20                88.72              6.69  ...   \n",
      "36                   49.07                74.07              6.65  ...   \n",
      "37                   25.00                38.64              6.66  ...   \n",
      "38                    8.11                32.43              6.69  ...   \n",
      "39                   27.78                50.00              6.69  ...   \n",
      "40                   40.00                53.33              6.69  ...   \n",
      "41                    0.00                 7.69              6.60  ...   \n",
      "42                   40.91                72.73              6.69  ...   \n",
      "43                   72.31                86.15              6.72  ...   \n",
      "44                   64.75                79.51              6.72  ...   \n",
      "45                   53.25                71.43              6.66  ...   \n",
      "46                   54.69                74.22              6.79  ...   \n",
      "47                    8.70                13.04              6.73  ...   \n",
      "72                   44.13                61.50              6.79  ...   \n",
      "73                   35.85                52.83              6.78  ...   \n",
      "74                   18.55                37.90              6.79  ...   \n",
      "75                   22.00                30.00              6.69  ...   \n",
      "76                   44.58                63.25              6.65  ...   \n",
      "77                   30.77                53.85              6.72  ...   \n",
      "78                   36.29                54.84              6.70  ...   \n",
      "79                   49.12                73.68              6.74  ...   \n",
      "...                    ...                  ...               ...  ...   \n",
      "40088                 0.00                 8.00              6.78  ...   \n",
      "40089                61.11                83.33              6.75  ...   \n",
      "40090                 0.00                 0.00              6.84  ...   \n",
      "40091                44.59                61.49              6.78  ...   \n",
      "40092                62.50                73.21              6.74  ...   \n",
      "40093                 0.00                 0.00              6.74  ...   \n",
      "40094                 9.30                16.28              6.88  ...   \n",
      "40095                31.82                45.45              6.95  ...   \n",
      "40096                 8.70                34.78              6.87  ...   \n",
      "40097                33.33                56.67              6.94  ...   \n",
      "40098                41.18                52.94              6.82  ...   \n",
      "40099                22.22                61.11              6.87  ...   \n",
      "40100                47.62                66.67              6.80  ...   \n",
      "40101                33.33                45.45              6.82  ...   \n",
      "40102                20.83                45.83              6.79  ...   \n",
      "40103                68.04                75.26              6.80  ...   \n",
      "40104                52.13                63.83              6.82  ...   \n",
      "40105                30.30                57.58              6.87  ...   \n",
      "40106                67.57                75.68              6.79  ...   \n",
      "40107                62.50                75.00              6.76  ...   \n",
      "40108                50.00                76.32              6.75  ...   \n",
      "40109                62.96                77.78              6.76  ...   \n",
      "40110                45.16                58.06              6.74  ...   \n",
      "40111                64.00                84.00              6.76  ...   \n",
      "40112                56.25                62.50              6.75  ...   \n",
      "40113                42.11                76.32              6.78  ...   \n",
      "40114                42.86                51.43              6.70  ...   \n",
      "40115                20.00                50.00              6.66  ...   \n",
      "40116                52.38                69.64              6.73  ...   \n",
      "40117                63.35                76.40              6.73  ...   \n",
      "\n",
      "       wide_1  wideOdds_1  wide_2  wideOdds_2  wide_3  wideOdds_3  trifecta  \\\n",
      "96        1-2         170     2-6         370     1-6         250     2-1-6   \n",
      "97        1-6         370     1-3         370     3-6         350     1-6-3   \n",
      "98        1-4         170     1-3         120     3-4         260     1-4-3   \n",
      "99        1-2         400     1-3         970     2-3         430     1-2-3   \n",
      "100       1-4         140     1-3         170     3-4         130     1-4-3   \n",
      "101       5-6         150     2-6         220     2-5         120     6-5-2   \n",
      "102       1-2         180     1-4         130     2-4         240     1-2-4   \n",
      "103       1-2         110     1-3         160     2-3         170     1-2-3   \n",
      "104       1-4         210     1-5         220     4-5         680     1-4-5   \n",
      "105       1-4         310     1-5         230     4-5        1100     1-4-5   \n",
      "36        1-4         170     1-5         170     4-5         290     1-4-5   \n",
      "37        4-5         610     5-6         890     4-6         470     5-4-6   \n",
      "38        2-3         220     3-4         180     2-4         270     3-2-4   \n",
      "39        3-4         150     1-3         150     1-4         250     3-4-1   \n",
      "40        1-4         130     1-3         130     3-4         210     1-4-3   \n",
      "41        1-2         390     2-3         150     1-3         190     2-1-3   \n",
      "42        1-3         120     3-4         150     1-4         180     3-1-4   \n",
      "43        1-2         110     1-3         150     2-3         180     1-2-3   \n",
      "44        1-3         240     1-6         460     3-6        1840     1-3-6   \n",
      "45        1-3         150     1-4         170     3-4         480     1-3-4   \n",
      "46        1-2         190     1-5         140     2-5         590     1-2-5   \n",
      "47        1-2         270     1-4         480     2-4         570     1-2-4   \n",
      "72        1-2         120     1-4         120     2-4         170     1-2-4   \n",
      "73        1-3         150     1-4         210     3-4         290     1-3-4   \n",
      "74        1-2         650     2-4         260     1-4         320     2-1-4   \n",
      "75        1-2         480     1-4         310     2-4         510     1-2-4   \n",
      "76        3-6         450     3-4         200     4-6         730     3-6-4   \n",
      "77        3-5         170     2-5         300     2-3         180     5-3-2   \n",
      "78        1-4         330     2-4         170     1-2         390     4-1-2   \n",
      "79        1-4         110     1-3         220     3-4         460     1-4-3   \n",
      "...       ...         ...     ...         ...     ...         ...       ...   \n",
      "40088     1-3         110     1-4         200     3-4         230     1-3-4   \n",
      "40089     1-4         180     1-5         200     4-5         810     1-4-5   \n",
      "40090     2-6         670     1-2         620     1-6        1650     2-6-1   \n",
      "40091     1-2         130     1-3         140     2-3         230     1-2-3   \n",
      "40092     1-3         150     1-2         110     2-3         180     1-3-2   \n",
      "40093     1-3         160     1-4         270     3-4         420     1-3-4   \n",
      "40094     1-3         180     1-2         250     2-3         440     1-3-2   \n",
      "40095     4-6         320     2-6         560     2-4         350     6-4-2   \n",
      "40096     2-4         130     2-3         300     3-4         600     2-4-3   \n",
      "40097     4-5        1030     3-4        1030     3-5         340     4-5-3   \n",
      "40098     1-4         120     1-2         100     2-4         220     1-4-2   \n",
      "40099     3-4         460     2-4         230     2-3         520     4-3-2   \n",
      "40100     1-4         180     1-5         270     4-5         460     1-4-5   \n",
      "40101     2-3         150     1-3         100     1-2         150     3-2-1   \n",
      "40102     1-2         210     1-3         150     2-3         240     1-2-3   \n",
      "40103     2-6         810     4-6        1030     2-4         830     6-2-4   \n",
      "40104     1-3         140     1-2         120     2-3         330     1-3-2   \n",
      "40105     1-2         150     2-3         260     1-3         130     2-1-3   \n",
      "40106     1-5         180     1-3         150     3-5         270     1-5-3   \n",
      "40107     1-6         340     3-6         660     1-3         170     6-1-3   \n",
      "40108     1-4         200     1-2         200     2-4         140     1-4-2   \n",
      "40109     1-3         150     1-6         290     3-6         530     1-3-6   \n",
      "40110     1-4         270     4-5         670     1-5         210     4-1-5   \n",
      "40111     1-2         230     1-5         150     2-5         740     1-2-5   \n",
      "40112     1-3         170     3-6         490     1-6         280     3-1-6   \n",
      "40113     1-3         220     1-2         190     2-3         330     1-3-2   \n",
      "40114     1-2         200     2-3         380     1-3         240     2-1-3   \n",
      "40115     1-2         130     1-6         690     2-6         860     1-2-6   \n",
      "40116     1-3         150     1-4         160     3-4         340     1-3-4   \n",
      "40117     1-2         200     1-5         420     2-5         600     1-2-5   \n",
      "\n",
      "       trifectaOdds   trio  trioOdds  \n",
      "96             4170  1-2-6       520  \n",
      "97             2960  1-3-6       780  \n",
      "98             1250  1-3-4       360  \n",
      "99             9230  1-2-3      2990  \n",
      "100             860  1-3-4       190  \n",
      "101            5580  2-5-6       240  \n",
      "102             990  1-2-4       390  \n",
      "103             670  1-2-3       270  \n",
      "104            2200  1-4-5      1110  \n",
      "105            1770  1-4-5       790  \n",
      "36              680  1-4-5       480  \n",
      "37            25980  4-5-6      2250  \n",
      "38             1490  2-3-4       410  \n",
      "39              940  1-3-4       220  \n",
      "40              670  1-3-4       280  \n",
      "41             6780  1-2-3       590  \n",
      "42              580  1-3-4       150  \n",
      "43              300  1-2-3       190  \n",
      "44             4080  1-3-6      2670  \n",
      "45             1340  1-3-4       650  \n",
      "46              880  1-2-5       390  \n",
      "47             2200  1-2-4       920  \n",
      "72              570  1-2-4       240  \n",
      "73             1330  1-3-4       650  \n",
      "74             7520  1-2-4       720  \n",
      "75             4540  1-2-4      1260  \n",
      "76             8710  3-4-6       760  \n",
      "77             4370  2-3-5       670  \n",
      "78             5070  1-2-4       730  \n",
      "79             1320  1-3-4       520  \n",
      "...             ...    ...       ...  \n",
      "40088           570  1-3-4       340  \n",
      "40089          1640  1-4-5       990  \n",
      "40090         20920  1-2-6      3470  \n",
      "40091           500  1-2-3       220  \n",
      "40092           890  1-2-3       230  \n",
      "40093           980  1-3-4       690  \n",
      "40094          1360  1-2-3       410  \n",
      "40095         12220  2-4-6      1180  \n",
      "40096          2500  2-3-4       960  \n",
      "40097         63250  3-4-5      6630  \n",
      "40098           870  1-2-4       270  \n",
      "40099          7110  2-3-4      1930  \n",
      "40100          2150  1-4-5      1060  \n",
      "40101          2330  1-2-3       180  \n",
      "40102           920  1-2-3       300  \n",
      "40103         97710  2-4-6     10340  \n",
      "40104           650  1-2-3       330  \n",
      "40105          6750  1-2-3       510  \n",
      "40106          1390  1-3-5       480  \n",
      "40107         11480  1-3-6       800  \n",
      "40108          2100  1-2-4       550  \n",
      "40109          1360  1-3-6       690  \n",
      "40110          7440  1-4-5       720  \n",
      "40111          1940  1-2-5       880  \n",
      "40112          5450  1-3-6      1350  \n",
      "40113          2110  1-2-3       660  \n",
      "40114          6380  1-2-3       620  \n",
      "40115          3040  1-2-6      1790  \n",
      "40116           950  1-3-4       410  \n",
      "40117          2170  1-2-5      1180  \n",
      "\n",
      "[23163 rows x 140 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fv_label_odds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1号艇についてtrainデータを使った正解率は0.7600107933081489,\n",
      "           testデータを使った正解率は0.6354413986617742\n",
      "\tvenue                : 0.063049\n",
      "\taveST_frame1         : 0.381143\n",
      "2号艇についてtrainデータを使った正解率は0.7598488936859147,\n",
      "           testデータを使った正解率は0.6205482408806389\n",
      "\tplaceRate_frame1     : 0.017527\n",
      "\texhibition_cource_1  : 0.021122\n",
      "\taveST_frame2         : 0.250877\n",
      "\tplaceRate_frame2     : 0.017868\n",
      "\tplace3Ratio_national_2 : 0.015919\n",
      "\taveST_frame3         : 0.018050\n",
      "\tplaceRate_frame3     : 0.015856\n",
      "\twin_rate_national_3  : 0.016546\n",
      "\taveST_frame4         : 0.018759\n",
      "\tplaceRate_frame4     : 0.015940\n",
      "\taveST_frame5         : 0.016798\n",
      "3号艇についてtrainデータを使った正解率は0.7665407447382623,\n",
      "           testデータを使った正解率は0.6164472264191668\n",
      "\taveST_frame2         : 0.017006\n",
      "\tplaceRate_frame2     : 0.018174\n",
      "\texhibition_cource_2  : 0.072917\n",
      "\taveST_frame3         : 0.179304\n",
      "\tplaceRate_frame3     : 0.033967\n",
      "\tplace2Ratio_national_3 : 0.022926\n",
      "\texhibitionTime_3     : 0.018311\n",
      "\taveST_frame4         : 0.019027\n",
      "\tplaceRate_frame4     : 0.022117\n",
      "\tplace2Ratio_national_4 : 0.015923\n",
      "4号艇についてtrainデータを使った正解率は0.7597409606044253,\n",
      "           testデータを使った正解率は0.6296136412691561\n",
      "\tplaceRate_frame1     : 0.015910\n",
      "\taveST_frame2         : 0.016797\n",
      "\twin_rate_national_3  : 0.016528\n",
      "\texhibition_cource_3  : 0.233929\n",
      "\taveST_frame4         : 0.074966\n",
      "\tplaceRate_frame4     : 0.022936\n",
      "\twin_rate_national_4  : 0.016322\n",
      "\texhibitionTime_4     : 0.015388\n",
      "\tplace2Ratio_national_5 : 0.017730\n",
      "\tplaceRate_frame6     : 0.021896\n",
      "\twin_rate_national_6  : 0.015704\n",
      "\tplace2Ratio_national_6 : 0.015154\n",
      "5号艇についてtrainデータを使った正解率は0.7804641122504048,\n",
      "           testデータを使った正解率は0.6686812000863371\n",
      "\taveST_frame1         : 0.019742\n",
      "\tplaceRate_frame1     : 0.018932\n",
      "\taveST_frame2         : 0.019514\n",
      "\taveST_frame3         : 0.016461\n",
      "\tplaceRate_frame3     : 0.016043\n",
      "\tplace2Ratio_national_3 : 0.016185\n",
      "\tplaceRate_frame4     : 0.017035\n",
      "\twin_rate_national_4  : 0.031716\n",
      "\texhibition_cource_4  : 0.216984\n",
      "\taveST_frame5         : 0.058673\n",
      "\tplaceRate_frame5     : 0.031503\n",
      "\tplace2Ratio_national_5 : 0.024073\n",
      "\texhibitionTime_5     : 0.019254\n",
      "\tmotor_place2Ratio_5  : 0.015479\n",
      "6号艇についてtrainデータを使った正解率は0.8206691851052348,\n",
      "           testデータを使った正解率は0.7440103604575868\n",
      "\taveST_frame1         : 0.015068\n",
      "\tplaceRate_frame1     : 0.024770\n",
      "\tplaceRate_frame2     : 0.025559\n",
      "\tplace2Ratio_national_5 : 0.015079\n",
      "\texhibition_cource_5  : 0.214264\n",
      "\taveST_frame6         : 0.054965\n",
      "\tplaceRate_frame6     : 0.023291\n",
      "\tboat_place3Ratio_6   : 0.088496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "上のセルで学習したclfを用いて色々と解析する。\n",
    "今このセルで行なっている解析は\n",
    "1. 各labelについて正解率を計算\n",
    "2. 最適化された結果の切片および各係数を表示\n",
    "3. テストデータについて、学習結果を適用した際に、ラベルが1になる確率を、実際のラベル　1 or　0で色分けしてヒストグラムを作成\n",
    "\n",
    "\"\"\"\n",
    "# 描画用の枠を用意\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
    "\n",
    "# 回収率計算用に、[predict_proba_array, test_t]を各要素にもつリストを作成\n",
    "predict_proba_array_list = []\n",
    "\n",
    "# 正解率の計算などのため、train data, test dataそれぞれについて、特徴量部分のarrayとlabel部分のarrayを作成\n",
    "train_x = train_data[:, :-num_labels]\n",
    "test_x = test_data[:, :-num_labels]\n",
    "\n",
    "for i, clf in enumerate(clf_list):\n",
    "    train_t = train_data[:, - num_labels + i]\n",
    "    test_t = test_data[:, - num_labels + i]\n",
    "    \n",
    "    # 正解率を計算\n",
    "    train_score = clf.score(train_x, train_t)\n",
    "    test_score = clf.score(test_x, test_t)\n",
    "    print(\"{2}号艇についてtrainデータを使った正解率は{0},\\n \\\n",
    "          testデータを使った正解率は{1}\".format(train_score, test_score, i + 1))\n",
    "    \n",
    "    # Feature Importance\n",
    "    fti = clf.feature_importances_\n",
    "    for j, fv in enumerate(fv_list):\n",
    "        if fti[j] > 0.015:\n",
    "            print('\\t{0:20s} : {1:>.6f}'.format(fv, fti[j]))\n",
    "\n",
    "    # テストデータについて、学習結果を適用した際に、ラベルが1になる確率を、実際のラベル　1 or　0で色分けしてヒストグラムを作成\n",
    "    predict_proba_array = clf.predict_proba(test_x)\n",
    "    \n",
    "    # listに格納しておく\n",
    "    predict_proba_array_list.append(predict_proba_array[:, 1])\n",
    "\n",
    "    # 結果が1 (1枠が一着 , 2枠以降が3着以内) だったものの推定確率\n",
    "    predict_proba_array_1 = predict_proba_array[:, 1][test_t==1]\n",
    "\n",
    "    # 結果が0 (1枠以外が一着, 1枠以外の場合は4着以降) だったものの推定確率\n",
    "    predict_proba_array_0 = predict_proba_array[:, 1][test_t==0]\n",
    "\n",
    "    # 積み上げヒストグラムを作成\n",
    "    title = \"frameNumber_{0}\".format(i + 1)\n",
    "    labels = {'predict_proba_array_1', 'predict_proba_array_0'}\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.hist([predict_proba_array_1, predict_proba_array_0], histtype=\"barstacked\", label=labels)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 最適なパラメータさがし\n",
    "- n_estimator...500くらいで十分\n",
    "- max_depth\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-90222f2175ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum_estimators\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_estimators_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mclf_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_list_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# 正解率の計算などのため、train data, test dataそれぞれについて、特徴量部分のarrayとlabel部分のarrayを作成\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-c70abe533066>\u001b[0m in \u001b[0;36mlearn_logistic_regression\u001b[1;34m(train_data, column_list_label, num_estimators, max_depth, max_features)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# Random Forest Classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mclf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_estimators_list = [10, 50, 100, 200, 500, 1000]\n",
    "max_depth = None\n",
    "max_features = None\n",
    "\n",
    "# 1つ目の要素に一号艇について、２つ目のリストは二号ていについての結果を、各num_estimatorsの値について格納していく\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for num_estimators in num_estimators_list:\n",
    "    clf_list, num_labels = learn_logistic_regression(train_data, column_list_label, num_estimators, max_depth, max_features)\n",
    "    # 正解率の計算などのため、train data, test dataそれぞれについて、特徴量部分のarrayとlabel部分のarrayを作成\n",
    "    train_x = train_data[:, :-num_labels]\n",
    "    test_x = test_data[:, :-num_labels]\n",
    "\n",
    "    for i, clf in enumerate(clf_list):\n",
    "        train_t = train_data[:, - num_labels + i]\n",
    "        test_t = test_data[:, - num_labels + i]\n",
    "\n",
    "        # 正解率を計算\n",
    "        train_score = clf.score(train_x, train_t)\n",
    "        test_score = clf.score(test_x, test_t)\n",
    "        \n",
    "        plt.subplot(2, 3, i+1)\n",
    "        # plt.scatter(num_estimators, train_score, c=\"red\")\n",
    "        plt.scatter(num_estimators, test_score, c=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_estimators = 100\n",
    "max_depth_list = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "max_features = None\n",
    "\n",
    "# 1つ目の要素に一号艇について、２つ目のリストは二号ていについての結果を、各num_estimatorsの値について格納していく\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    clf_list, num_labels = learn_logistic_regression(train_data, column_list_label, num_estimators, max_depth, max_features)\n",
    "    # 正解率の計算などのため、train data, test dataそれぞれについて、特徴量部分のarrayとlabel部分のarrayを作成\n",
    "    train_x = train_data[:, :-num_labels]\n",
    "    test_x = test_data[:, :-num_labels]\n",
    "\n",
    "    for i, clf in enumerate(clf_list):\n",
    "        train_t = train_data[:, - num_labels + i]\n",
    "        test_t = test_data[:, - num_labels + i]\n",
    "\n",
    "        # 正解率を計算\n",
    "        train_score = clf.score(train_x, train_t)\n",
    "        test_score = clf.score(test_x, test_t)\n",
    "        \n",
    "        plt.subplot(2, 3, i+1)\n",
    "        # plt.scatter(max_depth, train_score, c=\"red\")\n",
    "        plt.scatter(max_depth, test_score, c=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-59-fbe831f4ff6b>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-59-fbe831f4ff6b>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    for max_featuresuremax_featuresax_features_list:\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "num_estimators = 100\n",
    "max_depth = None\n",
    "max_features_list = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55]\n",
    "\n",
    "# 1つ目の要素に一号艇について、２つ目のリストは二号ていについての結果を、各num_estimatorsの値について格納していく\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for max_featuresuremax_featuresax_features_list:\n",
    "    clf_list, num_labels = learn_logistic_regression(train_data, column_list_label, num_estimators, max_depth, max_features)\n",
    "    # 正解率の計算などのため、train data, test dataそれぞれについて、特徴量部分のarrayとlabel部分のarrayを作成\n",
    "    train_x = train_data[:, :-num_labels]\n",
    "    test_x = test_data[:, :-num_labels]\n",
    "\n",
    "    for i, clf in enumerate(clf_list):\n",
    "        train_t = train_data[:, - num_labels + i]\n",
    "        test_t = test_data[:, - num_labels + i]\n",
    "\n",
    "        # 正解率を計算\n",
    "        train_score = clf.score(train_x, train_t)\n",
    "        test_score = clf.score(test_x, test_t)\n",
    "        \n",
    "        plt.subplot(2, 3, i+1)\n",
    "        # plt.scatter(max_depth, train_score, c=\"red\")\n",
    "        plmax_featuresturesuresturesturesres(max_features, test_score, c=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 考察\n",
    "- 正解率はいずれのラベルに対しても6割から7割程度にとどまるが、test dataとtraining dataで同程度の正解率をだす。\n",
    "確率ごとにプロットをしてみると、\n",
    "- predict_probaが小さい時は実際に0ラベル、predict_probaが大きい時は実際に1ラベルであることがかなり多くなっている。\n",
    "- 正解率を下げているのは実際に判断が難しいところ（0.3 < predict_proba < 0.7くらいの場所） であり、predict_probaが高いところ、低いところを抽出して用いることで十分に予測器として使用可能\n",
    "- 1着以外が1位になる，荒れるレースの予測や、1着を1枠に固定し、2, 3を高いprobabilityを示すものでbox買するといったオプションが考えられる。\n",
    "\n",
    "そこで、以下のセルにおいては掛け方を色々してみた時の回収率計算を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PredProb_1  PredProb_2  PredProb_3  PredProb_4  PredProb_5  PredProb_6  \\\n",
      "0       0.817770    0.598635    0.438678    0.291206    0.443241    0.341548   \n",
      "1       0.499031    0.502284    0.517262    0.699576    0.186778    0.168857   \n",
      "2       0.231455    0.757978    0.820562    0.269349    0.337257    0.338260   \n",
      "3       0.338126    0.620455    0.500852    0.738027    0.466430    0.056964   \n",
      "4       0.251845    0.778745    0.693487    0.136490    0.662731    0.450072   \n",
      "5       0.437841    0.237006    0.750571    0.401157    0.623871    0.442956   \n",
      "6       0.336111    0.838110    0.571616    0.234415    0.716691    0.118667   \n",
      "7       0.405049    0.828341    0.721230    0.549706    0.160172    0.387712   \n",
      "8       0.609345    0.756088    0.185841    0.356306    0.516707    0.695229   \n",
      "9       0.840584    0.609940    0.636547    0.562113    0.055586    0.522335   \n",
      "10      0.693462    0.508160    0.380090    0.226165    0.475818    0.749844   \n",
      "11      0.648820    0.486163    0.649333    0.372732    0.406926    0.139617   \n",
      "12      0.769204    0.675009    0.323037    0.362512    0.512382    0.371866   \n",
      "13      0.372312    0.792484    0.550854    0.380449    0.138094    0.253706   \n",
      "14      0.402071    0.678648    0.498714    0.442904    0.280054    0.073041   \n",
      "15      0.540080    0.608592    0.605715    0.659844    0.289450    0.092913   \n",
      "16      0.709468    0.508865    0.606536    0.310228    0.282260    0.255159   \n",
      "17      0.757743    0.517716    0.355883    0.251944    0.717736    0.156738   \n",
      "18      0.822276    0.286886    0.644518    0.299833    0.315513    0.597906   \n",
      "19      0.714001    0.470890    0.577766    0.291948    0.148578    0.448473   \n",
      "20      0.815727    0.562556    0.559370    0.575948    0.355764    0.061863   \n",
      "21      0.811600    0.528504    0.680192    0.410857    0.248765    0.142623   \n",
      "22      0.748620    0.617177    0.222991    0.765805    0.248984    0.387524   \n",
      "23      0.775290    0.735214    0.753004    0.453370    0.220261    0.119005   \n",
      "24      0.768463    0.729354    0.734815    0.484268    0.235322    0.100682   \n",
      "25      0.825226    0.729153    0.557949    0.493734    0.273029    0.061660   \n",
      "26      0.511262    0.815546    0.389275    0.195230    0.515390    0.090902   \n",
      "27      0.591212    0.340572    0.802472    0.562260    0.426746    0.157787   \n",
      "28      0.548262    0.719758    0.365474    0.308729    0.701491    0.145824   \n",
      "29      0.778842    0.798009    0.422549    0.398460    0.314899    0.087314   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "4603    0.365023    0.635969    0.703094    0.565667    0.251315    0.187400   \n",
      "4604    0.853963    0.279840    0.505427    0.446678    0.453898    0.380568   \n",
      "4605    0.295910    0.582819    0.729680    0.331312    0.287056    0.186839   \n",
      "4606    0.608079    0.635777    0.583570    0.462301    0.202349    0.327787   \n",
      "4607    0.798818    0.729626    0.504669    0.377452    0.321329    0.311644   \n",
      "4608    0.178949    0.774597    0.668462    0.414787    0.310958    0.200036   \n",
      "4609    0.250272    0.426725    0.587454    0.649328    0.297752    0.400533   \n",
      "4610    0.300472    0.821131    0.529261    0.539583    0.031012    0.263659   \n",
      "4611    0.241968    0.855625    0.342304    0.345889    0.677045    0.088440   \n",
      "4612    0.461767    0.649659    0.385695    0.360539    0.565372    0.269111   \n",
      "4613    0.664786    0.751076    0.558784    0.589928    0.249952    0.089675   \n",
      "4614    0.579894    0.692297    0.575971    0.516495    0.509829    0.074493   \n",
      "4615    0.706223    0.589745    0.353281    0.737143    0.236574    0.468805   \n",
      "4616    0.686282    0.729524    0.721476    0.381597    0.178907    0.055767   \n",
      "4617    0.049271    0.742923    0.566205    0.555495    0.499058    0.258486   \n",
      "4618    0.622546    0.545619    0.657726    0.303024    0.219596    0.363978   \n",
      "4619    0.517414    0.590981    0.714728    0.616676    0.319141    0.087109   \n",
      "4620    0.732818    0.478984    0.693335    0.215063    0.327956    0.354691   \n",
      "4621    0.703278    0.581903    0.495526    0.433395    0.362126    0.230234   \n",
      "4622    0.718029    0.646966    0.603663    0.422691    0.291085    0.185306   \n",
      "4623    0.602863    0.476772    0.549178    0.459816    0.310071    0.523472   \n",
      "4624    0.669145    0.632683    0.611800    0.412238    0.389123    0.212030   \n",
      "4625    0.594136    0.629083    0.733188    0.535286    0.408937    0.196193   \n",
      "4626    0.678776    0.467431    0.524813    0.436053    0.406626    0.265318   \n",
      "4627    0.808498    0.573613    0.555889    0.407078    0.243026    0.236765   \n",
      "4628    0.662395    0.612060    0.505660    0.408686    0.313351    0.409682   \n",
      "4629    0.704587    0.457854    0.513896    0.422799    0.350549    0.372668   \n",
      "4630    0.655022    0.540930    0.477286    0.463494    0.320758    0.208848   \n",
      "4631    0.753249    0.605657    0.705396    0.422601    0.325758    0.208646   \n",
      "4632    0.582805    0.569369    0.483445    0.439029    0.495779    0.235899   \n",
      "\n",
      "     win  winOdds place_1  placeOdds_1  ... wide_1  wideOdds_1 wide_2  \\\n",
      "0      2      360       2          110  ...    1-2         110    2-6   \n",
      "1      1      210       1          100  ...    1-4         110    1-6   \n",
      "2      2      450       2          150  ...    1-2         240    2-3   \n",
      "3      3      680       3          320  ...    1-3         810    2-3   \n",
      "4      1      290       1          150  ...    1-5         220    1-3   \n",
      "5      1      210       1          110  ...    1-3         140    1-2   \n",
      "6      3      340       3          210  ...    1-3         230    3-5   \n",
      "7      2      220       2          100  ...    1-2         360    2-4   \n",
      "8      1      210       1          210  ...    1-5         340    1-6   \n",
      "9      6     7650       6          370  ...    1-6         180    4-6   \n",
      "10     5      660       5          140  ...    1-5         170    2-5   \n",
      "11     1      120       1          100  ...    1-5         320    1-4   \n",
      "12     1      190       1          100  ...    1-3         240    1-5   \n",
      "13     6     2220       6          270  ...    1-6         420    3-6   \n",
      "14     2      410       2          130  ...    1-2         140    2-4   \n",
      "15     1      190       1          100  ...    1-2         120    1-3   \n",
      "16     1      100       1          100  ...    1-3         150    1-4   \n",
      "17     1      140       1          100  ...    1-2         140    1-5   \n",
      "18     1      120       1          100  ...    1-6         120    1-3   \n",
      "19     1      100       1          100  ...    1-2         110    1-6   \n",
      "20     1      100       1          100  ...    1-2         150    1-4   \n",
      "21     1      120       1          100  ...    1-5         240    1-3   \n",
      "22     4     1190       4          130  ...    1-4         140    4-6   \n",
      "23     1      100       1          100  ...    1-3         120    1-2   \n",
      "24     1      110       1          100  ...    1-3         130    1-4   \n",
      "25     3      420       3          330  ...    3-5         730    3-4   \n",
      "26     2      130       2          180  ...    1-2         140    2-5   \n",
      "27     1      200       1          120  ...    1-3         150    1-2   \n",
      "28              0       3          540  ...    2-3         500    3-5   \n",
      "29     2      280       2          280  ...    2-5         530    1-2   \n",
      "...   ..      ...     ...          ...  ...    ...         ...    ...   \n",
      "4603   1      140       1          100  ...    1-3         110    1-4   \n",
      "4604   1      100       1          100  ...    1-4         180    1-5   \n",
      "4605   2      260       2          160  ...    2-6         670    1-2   \n",
      "4606   1      100       1          100  ...    1-2         130    1-3   \n",
      "4607   1      130       1          110  ...    1-3         150    1-2   \n",
      "4608   1      110       1          100  ...    1-3         160    1-4   \n",
      "4609   1      120       1          100  ...    1-3         180    1-2   \n",
      "4610   6     2770       6          450  ...    4-6         320    2-6   \n",
      "4611   2      440       2          120  ...    2-4         130    2-3   \n",
      "4612   4     1080       4          220  ...    4-5        1030    3-4   \n",
      "4613   1      100       1          100  ...    1-4         120    1-2   \n",
      "4614   4      440       4          150  ...    3-4         460    2-4   \n",
      "4615   1      110       1          100  ...    1-4         180    1-5   \n",
      "4616   3      190       3          110  ...    2-3         150    1-3   \n",
      "4617   1      210       1          120  ...    1-2         210    1-3   \n",
      "4618   6     1370       6          570  ...    2-6         810    4-6   \n",
      "4619   1      110       1          100  ...    1-3         140    1-2   \n",
      "4620   2     1140       2          170  ...    1-2         150    2-3   \n",
      "4621   1      100       1          110  ...    1-5         180    1-3   \n",
      "4622   6      680       6          480  ...    1-6         340    3-6   \n",
      "4623   1      160       1          110  ...    1-4         200    1-2   \n",
      "4624   1      120       1          100  ...    1-3         150    1-6   \n",
      "4625   4     1510       4          590  ...    1-4         270    4-5   \n",
      "4626   1      130       1          170  ...    1-2         230    1-5   \n",
      "4627   3      380       3          110  ...    1-3         170    3-6   \n",
      "4628   1      130       1          110  ...    1-3         220    1-2   \n",
      "4629   2      530       2          180  ...    1-2         200    2-3   \n",
      "4630   1      120       1          100  ...    1-2         130    1-6   \n",
      "4631   1      100       1          160  ...    1-3         150    1-4   \n",
      "4632   1      110       1          100  ...    1-2         200    1-5   \n",
      "\n",
      "      wideOdds_2 wide_3  wideOdds_3 trifecta  trifectaOdds   trio  trioOdds  \n",
      "0            380    1-6         280    2-1-6          3140  1-2-6       650  \n",
      "1            310    4-6         280    1-4-6          1100  1-4-6       500  \n",
      "2            180    1-3         170    2-1-3          4440  1-2-3       350  \n",
      "3            910    1-2         430    3-1-2         12450  1-2-3      1310  \n",
      "4            160    3-5         330    1-5-3          2740  1-3-5       570  \n",
      "5            330    2-3         220    1-3-2          1030  1-2-3       380  \n",
      "6            130    1-5         320    3-1-5          2340  1-3-5       520  \n",
      "7            250    1-4         730    2-1-4          2620  1-2-4       780  \n",
      "8            170    5-6         340    1-5-6          4420  1-5-6       620  \n",
      "9            340    1-4         150    6-1-4         14250  1-4-6       290  \n",
      "10           810    1-2         360    5-1-2          9220  1-2-5      1530  \n",
      "11           270    4-5         670    1-5-4          3540  1-4-5       940  \n",
      "12           190    3-5         890    1-3-5          2530  1-3-5      1110  \n",
      "13           900    1-3         250    6-1-3         35060  1-3-6      1850  \n",
      "14           180    1-4         140    2-1-4          2030  1-2-4       240  \n",
      "15           110    2-3         230    1-2-3           770  1-2-3       340  \n",
      "16           280    3-4         270    1-3-4           930  1-3-4       470  \n",
      "17           150    2-5         190    1-2-5           530  1-2-5       300  \n",
      "18           100    3-6         140    1-6-3           490  1-3-6       150  \n",
      "19           140    2-6         240    1-2-6           520  1-2-6       290  \n",
      "20           160    2-4         250    1-2-4           570  1-2-4       290  \n",
      "21           170    3-5         720    1-5-3          1690  1-3-5       600  \n",
      "22           550    1-6         310    4-1-6          8220  1-4-6      1160  \n",
      "23           150    2-3         240    1-3-2           630  1-2-3       280  \n",
      "24           200    3-4         350    1-3-4           640  1-3-4       370  \n",
      "25           590    4-5         500    3-5-4         21880  3-4-5      3900  \n",
      "26           140    1-5         180    2-1-5           950  1-2-5       210  \n",
      "27           240    2-3         320    1-3-2          1870  1-2-3       590  \n",
      "28           470    2-5         210    3-2-5         43660  2-3-5      3090  \n",
      "29           150    1-5         330    2-5-1         28830  1-2-5       770  \n",
      "...          ...    ...         ...      ...           ...    ...       ...  \n",
      "4603         200    3-4         230    1-3-4           570  1-3-4       340  \n",
      "4604         200    4-5         810    1-4-5          1640  1-4-5       990  \n",
      "4605         620    1-6        1650    2-6-1         20920  1-2-6      3470  \n",
      "4606         140    2-3         230    1-2-3           500  1-2-3       220  \n",
      "4607         110    2-3         180    1-3-2           890  1-2-3       230  \n",
      "4608         270    3-4         420    1-3-4           980  1-3-4       690  \n",
      "4609         250    2-3         440    1-3-2          1360  1-2-3       410  \n",
      "4610         560    2-4         350    6-4-2         12220  2-4-6      1180  \n",
      "4611         300    3-4         600    2-4-3          2500  2-3-4       960  \n",
      "4612        1030    3-5         340    4-5-3         63250  3-4-5      6630  \n",
      "4613         100    2-4         220    1-4-2           870  1-2-4       270  \n",
      "4614         230    2-3         520    4-3-2          7110  2-3-4      1930  \n",
      "4615         270    4-5         460    1-4-5          2150  1-4-5      1060  \n",
      "4616         100    1-2         150    3-2-1          2330  1-2-3       180  \n",
      "4617         150    2-3         240    1-2-3           920  1-2-3       300  \n",
      "4618        1030    2-4         830    6-2-4         97710  2-4-6     10340  \n",
      "4619         120    2-3         330    1-3-2           650  1-2-3       330  \n",
      "4620         260    1-3         130    2-1-3          6750  1-2-3       510  \n",
      "4621         150    3-5         270    1-5-3          1390  1-3-5       480  \n",
      "4622         660    1-3         170    6-1-3         11480  1-3-6       800  \n",
      "4623         200    2-4         140    1-4-2          2100  1-2-4       550  \n",
      "4624         290    3-6         530    1-3-6          1360  1-3-6       690  \n",
      "4625         670    1-5         210    4-1-5          7440  1-4-5       720  \n",
      "4626         150    2-5         740    1-2-5          1940  1-2-5       880  \n",
      "4627         490    1-6         280    3-1-6          5450  1-3-6      1350  \n",
      "4628         190    2-3         330    1-3-2          2110  1-2-3       660  \n",
      "4629         380    1-3         240    2-1-3          6380  1-2-3       620  \n",
      "4630         690    2-6         860    1-2-6          3040  1-2-6      1790  \n",
      "4631         160    3-4         340    1-3-4           950  1-3-4       410  \n",
      "4632         420    2-5         600    1-2-5          2170  1-2-5      1180  \n",
      "\n",
      "[4633 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# 計算用dfを作成\n",
    "# 6列目までが上の解析によって求めた確率(1号艇が1位になる率, 2-6号艇が3位以内に入る確率)\n",
    "# 7列目以降にオッズ関係の値を格納\n",
    "\n",
    "for_calc_refund_rate_df = pd.DataFrame(np.vstack(predict_proba_array_list).T, columns=[\"PredProb_{0}\".format(i) for i in range(1, 7)])\n",
    "for odds_column_name in odds_list:\n",
    "    # TODO intで入れられるものはintで。無理なものはとりあえずobjectのままで格納\n",
    "    for_calc_refund_rate_df[odds_column_name] = fv_label_odds_df[odds_column_name][train_size:].values\n",
    "\n",
    "print(for_calc_refund_rate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "確率0.6以上で1に単勝betした場合、的中率は0.6799233349305223, 回収率は0.9208433157642549\n",
      "確率0.7以上で1に単勝betした場合、的中率は0.7285714285714285, 回収率は0.9169747899159664\n",
      "確率0.8以上で1に単勝betした場合、的中率は0.832579185520362, 回収率は0.9307692307692308\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-0c7734f5556d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mreturn_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfor_calc_refund_rate_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"winOdds\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreturn_boolean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"確率{0}以上で1に単勝betした場合、的中率は{1}, 回収率は{2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_boolean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbet\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# 確率x_1以上のときのみ、1に単勝賭けした時の回収率\n",
    "x_1_list = [0.6, 0.7, 0.8, 0.9]\n",
    "for x_1 in x_1_list:\n",
    "    bet = sum(for_calc_refund_rate_df[\"PredProb_1\"] > x_1)\n",
    "\n",
    "    return_boolean = (for_calc_refund_rate_df[\"PredProb_1\"] > x_1) & (for_calc_refund_rate_df[\"win\"] == \"1\")\n",
    "    return_ = sum(for_calc_refund_rate_df[\"winOdds\"][return_boolean])\n",
    "\n",
    "    print(\"確率{0}以上で1に単勝betした場合、的中率は{1}, 回収率は{2}\".format(x_1, sum(return_boolean) / bet, return_ / (bet * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1が0.7以上かつ、p2-6が0.5以上で2連単betすると収益は-5110, 回収率は0.9643156424581005\n",
      "p1が0.7以上かつ、p2-6が0.6以上で2連単betすると収益は-1820, 回収率は0.9775862068965517\n",
      "p1が0.7以上かつ、p2-6が0.7以上で2連単betすると収益は-2000, 回収率は0.9493670886075949\n",
      "p1が0.7以上かつ、p2-6が0.8以上で2連単betすると収益は-410, 回収率は0.9605769230769231\n",
      "p1が0.75以上かつ、p2-6が0.5以上で2連単betすると収益は-1310, 回収率は0.9863966770508826\n",
      "p1が0.75以上かつ、p2-6が0.6以上で2連単betすると収益は-1510, 回収率は0.9719330855018588\n",
      "p1が0.75以上かつ、p2-6が0.7以上で2連単betすると収益は-3320, 回収率は0.8727969348659004\n",
      "p1が0.75以上かつ、p2-6が0.8以上で2連単betすると収益は-640, 回収率は0.9058823529411765\n",
      "p1が0.8以上かつ、p2-6が0.5以上で2連単betすると収益は-1140, 回収率は0.9786915887850467\n",
      "p1が0.8以上かつ、p2-6が0.6以上で2連単betすると収益は-2120, 回収率は0.9288590604026845\n",
      "p1が0.8以上かつ、p2-6が0.7以上で2連単betすると収益は-1780, 回収率は0.8851612903225806\n",
      "p1が0.8以上かつ、p2-6が0.8以上で2連単betすると収益は130, 回収率は1.0282608695652173\n"
     ]
    }
   ],
   "source": [
    "# 1号艇の勝率x_1以上の時、他の艇で3位以内率がx_2超えがあった場合に、1-XY..の形で2連単bet\n",
    "\n",
    "x_1_list = [0.7, 0.75, 0.8]\n",
    "x_2_list = [0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        income = 0\n",
    "        bet = 0\n",
    "\n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                for j in range(2, 7):\n",
    "                    if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                        bet_num = \"1-{0}\".format(j)\n",
    "                        bet = bet + 100\n",
    "                        if row[\"exacta\"] == bet_num:\n",
    "                            income = income + row[\"exactaOdds\"]\n",
    "        print(\"p1が{0}以上かつ、p2-6が{1}以上で2連単betすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1が0.6以上かつ、p2-6が0.6以上で3連単betすると収益は-319020, 回収率は0.8164019337016575\n",
      "p1が0.6以上かつ、p2-6が0.7以上で3連単betすると収益は-118740, 回収率は0.8426033934252386\n",
      "p1が0.6以上かつ、p2-6が0.8以上で3連単betすると収益は-14100, 回収率は0.9392241379310344\n",
      "p1が0.7以上かつ、p2-6が0.6以上で3連単betすると収益は-129240, 回収率は0.8545904590459046\n",
      "p1が0.7以上かつ、p2-6が0.7以上で3連単betすると収益は-43630, 回収率は0.8941019417475728\n",
      "p1が0.7以上かつ、p2-6が0.8以上で3連単betすると収益は-12520, 回収率は0.9045731707317073\n",
      "p1が0.8以上かつ、p2-6が0.6以上で3連単betすると収益は-33360, 回収率は0.9034722222222222\n",
      "p1が0.8以上かつ、p2-6が0.7以上で3連単betすると収益は-12060, 回収率は0.9257389162561577\n",
      "p1が0.8以上かつ、p2-6が0.8以上で3連単betすると収益は4620, 回収率は1.0916666666666666\n"
     ]
    }
   ],
   "source": [
    "# 1号艇の勝率x_1以上の時、他の艇で3位以内率x_2超えがあった場合に、1-X-9と1-9-Xの形で3連単bet\n",
    "x_1_list = [0.6, 0.7, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        \n",
    "        income = 0\n",
    "        bet = 0\n",
    "        \n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                for j in range(2, 7):\n",
    "                    if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                        for k in range(2, 7):\n",
    "                            if k is not j:\n",
    "                                bet = bet + 200\n",
    "                                bet_num_1 = \"1-{0}-{1}\".format(j, k)\n",
    "                                bet_num_2 = \"1-{0}-{1}\".format(k, j)\n",
    "                                # print(bet_num_1, bet_num_2, row[\"trifecta\"], row[\"trifectaOdds\"])\n",
    "                                if row[\"trifecta\"] == bet_num_1 or row[\"trifecta\"] == bet_num_2:\n",
    "                                    income = income + row[\"trifectaOdds\"]\n",
    "        print(\"p1が{0}以上かつ、p2-6が{1}以上で3連単betすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上と同じノリで2着固定。すなわち、\n",
    "# 1号艇の勝率x_1以上の時、他の艇で3位以内率x_2超えがあった場合に、1-X-9の形で3連単bet\n",
    "x_1_list = [0.5, 0.6, 0.7, 0.8]\n",
    "x_2_list = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        \n",
    "        income = 0\n",
    "        bet = 0\n",
    "        \n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                for j in range(2, 7):\n",
    "                    if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                        for k in range(2, 7):\n",
    "                            if k is not j:\n",
    "                                bet = bet + 100\n",
    "                                bet_num = \"1-{0}-{1}\".format(j, k)\n",
    "                                if row[\"trifecta\"] == bet_num:\n",
    "                                    income = income + row[\"trifectaOdds\"]\n",
    "        print(\"p1が{0}以上かつ、p2-6が{1}以上で3連単betすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1号艇の勝率x_1以上の時、他の艇で3位以内率x_2以下が2艇以上あった場合に、1頭で、2割以下艇を外した残りを2, 3着boxにして買う\n",
    "x_1_list = [0.6, 0.7, 0.8]\n",
    "x_2_list = [0.4, 0.3, 0.2]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        \n",
    "        income = 0\n",
    "        bet = 0\n",
    "        \n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                outers = (row[[\"PredProb_{0}\".format(n) for n in range(2, 7)]] < x_2)\n",
    "                num_outers = sum(outers)\n",
    "                if (num_outers > 1):\n",
    "                    for j in range(2, 7):\n",
    "                        if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                            for k in range(2, 7):\n",
    "                                if k is not j and row[\"PredProb_{0}\".format(k)] > x_2:\n",
    "                                    bet = bet + 100\n",
    "                                    bet_num = \"1-{0}-{1}\".format(j, k)\n",
    "                                    if row[\"trifecta\"] == bet_num:\n",
    "                                        income = income + row[\"trifectaOdds\"]\n",
    "        print(\"p1が{0}以上かつ、p2-6が{1}以上で3連単betすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'termcolor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-a4144e52ca6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"p1が{0}以上かつ、p2-6が{1}以上で3連単betすると収益は{2}, 回収率は{3}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincome\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincome\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mincome\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtermcolor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'termcolor' is not defined"
     ]
    }
   ],
   "source": [
    "# 1号艇の勝率x_1以上の時、他の艇で3位以内率x_2以上が2艇以上あった場合に、1頭で、x_2以上艇を2, 3着boxにして買う\n",
    "x_1_list = [0.5, 0.6, 0.7, 0.75, 0.8]\n",
    "x_2_list = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        \n",
    "        income = 0\n",
    "        bet = 0\n",
    "        \n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                for j in range(2, 7):\n",
    "                    if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                        for k in range(2, 7):\n",
    "                            if k is not j and row[\"PredProb_{0}\".format(k)] > x_2:\n",
    "                                bet = bet + 100\n",
    "                                bet_num = \"1-{0}-{1}\".format(j, k)\n",
    "                                if row[\"trifecta\"] == bet_num:\n",
    "                                    income = income + row[\"trifectaOdds\"]\n",
    "                                # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "        try:\n",
    "            text = \"p1が{0}以上かつ、p2-6が{1}以上で3連単betすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet)\n",
    "            if (income / bet) < 1:\n",
    "                text = termcolor.colored(text, \"red\")\n",
    "            print(text)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"投票候補なし\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1が0.6以上かつ、p2が0.6以上かつp3が0.3で3連単betすると収益は-217180, 回収率は0.8101573426573426\n",
      "p1が0.6以上かつ、p2が0.6以上かつp3が0.4で3連単betすると収益は-180300, 回収率は0.77286470143613\n",
      "p1が0.6以上かつ、p2が0.6以上かつp3が0.5で3連単betすると収益は-90760, 回収率は0.810601001669449\n",
      "p1が0.6以上かつ、p2が0.6以上かつp3が0.6で3連単betすると収益は-45200, 回収率は0.8144499178981938\n",
      "p1が0.6以上かつ、p2が0.7以上かつp3が0.3で3連単betすると収益は-38090, 回収率は0.9003401360544218\n",
      "p1が0.6以上かつ、p2が0.7以上かつp3が0.4で3連単betすると収益は-47910, 回収率は0.8132891660171473\n",
      "p1が0.6以上かつ、p2が0.7以上かつp3が0.5で3連単betすると収益は-26440, 回収率は0.8242021276595745\n",
      "p1が0.6以上かつ、p2が0.7以上かつp3が0.6で3連単betすると収益は-7780, 回収率は0.8942934782608696\n",
      "p1が0.6以上かつ、p2が0.7以上かつp3が0.7で3連単betすると収益は-2200, 回収率は0.8854166666666666\n",
      "p1が0.6以上かつ、p2が0.8以上かつp3が0.3で3連単betすると収益は-5540, 回収率は0.9024647887323943\n",
      "p1が0.6以上かつ、p2が0.8以上かつp3が0.4で3連単betすると収益は-5930, 回収率は0.8471649484536082\n",
      "p1が0.6以上かつ、p2が0.8以上かつp3が0.5で3連単betすると収益は-910, 回収率は0.9570754716981132\n",
      "p1が0.6以上かつ、p2が0.8以上かつp3が0.6で3連単betすると収益は-1690, 回収率は0.8079545454545455\n",
      "p1が0.6以上かつ、p2が0.8以上かつp3が0.7で3連単betすると収益は740, 回収率は1.6166666666666667\n",
      "p1=0.6, p2=0.8, p3=0.8の時、投票候補なし\n",
      "p1が0.7以上かつ、p2が0.6以上かつp3が0.3で3連単betすると収益は-108830, 回収率は0.8172766957689724\n",
      "p1が0.7以上かつ、p2が0.6以上かつp3が0.4で3連単betすると収益は-99000, 回収率は0.756037456875308\n",
      "p1が0.7以上かつ、p2が0.6以上かつp3が0.5で3連単betすると収益は-46930, 回収率は0.8033109807208717\n",
      "p1が0.7以上かつ、p2が0.6以上かつp3が0.6で3連単betすると収益は-14620, 回収率は0.8730902777777778\n",
      "p1が0.7以上かつ、p2が0.7以上かつp3が0.3で3連単betすると収益は-25930, 回収率は0.862221041445271\n",
      "p1が0.7以上かつ、p2が0.7以上かつp3が0.4で3連単betすると収益は-33730, 回収率は0.73016\n",
      "p1が0.7以上かつ、p2が0.7以上かつp3が0.5で3連単betすると収益は-19110, 回収率は0.7316011235955057\n",
      "p1が0.7以上かつ、p2が0.7以上かつp3が0.6で3連単betすると収益は-5070, 回収率は0.8508823529411764\n",
      "p1が0.7以上かつ、p2が0.7以上かつp3が0.7で3連単betすると収益は-2300, 回収率は0.6973684210526315\n",
      "p1が0.7以上かつ、p2が0.8以上かつp3が0.3で3連単betすると収益は1440, 回収率は1.0705882352941176\n",
      "p1が0.7以上かつ、p2が0.8以上かつp3が0.4で3連単betすると収益は-1170, 回収率は0.9113636363636364\n",
      "p1が0.7以上かつ、p2が0.8以上かつp3が0.5で3連単betすると収益は-740, 回収率は0.9026315789473685\n",
      "p1が0.7以上かつ、p2が0.8以上かつp3が0.6で3連単betすると収益は-1090, 回収率は0.6366666666666667\n",
      "p1が0.7以上かつ、p2が0.8以上かつp3が0.7で3連単betすると収益は-400, 回収率は0.0\n",
      "p1=0.7, p2=0.8, p3=0.8の時、投票候補なし\n",
      "p1が0.75以上かつ、p2が0.6以上かつp3が0.3で3連単betすると収益は-38120, 回収率は0.8832107843137255\n",
      "p1が0.75以上かつ、p2が0.6以上かつp3が0.4で3連単betすると収益は-44640, 回収率は0.7948529411764705\n",
      "p1が0.75以上かつ、p2が0.6以上かつp3が0.5で3連単betすると収益は-10190, 回収率は0.9205148205928237\n",
      "p1が0.75以上かつ、p2が0.6以上かつp3が0.6で3連単betすると収益は-1920, 回収率は0.9701863354037267\n",
      "p1が0.75以上かつ、p2が0.7以上かつp3が0.3で3連単betすると収益は-6930, 回収率は0.9324561403508772\n",
      "p1が0.75以上かつ、p2が0.7以上かつp3が0.4で3連単betすると収益は-16840, 回収率は0.7471471471471471\n",
      "p1が0.75以上かつ、p2が0.7以上かつp3が0.5で3連単betすると収益は-5490, 回収率は0.8516216216216216\n",
      "p1が0.75以上かつ、p2が0.7以上かつp3が0.6で3連単betすると収益は-790, 回収率は0.9601010101010101\n",
      "p1が0.75以上かつ、p2が0.7以上かつp3が0.7で3連単betすると収益は-720, 回収率は0.82\n",
      "p1が0.75以上かつ、p2が0.8以上かつp3が0.3で3連単betすると収益は160, 回収率は1.019047619047619\n",
      "p1が0.75以上かつ、p2が0.8以上かつp3が0.4で3連単betすると収益は740, 回収率は1.148\n",
      "p1が0.75以上かつ、p2が0.8以上かつp3が0.5で3連単betすると収益は1140, 回収率は1.4384615384615385\n",
      "p1が0.75以上かつ、p2が0.8以上かつp3が0.6で3連単betすると収益は-40, 回収率は0.9714285714285714\n",
      "p1が0.75以上かつ、p2が0.8以上かつp3が0.7で3連単betすると収益は-200, 回収率は0.0\n",
      "p1=0.75, p2=0.8, p3=0.8の時、投票候補なし\n",
      "p1が0.8以上かつ、p2が0.6以上かつp3が0.3で3連単betすると収益は-9230, 回収率は0.9084325396825397\n",
      "p1が0.8以上かつ、p2が0.6以上かつp3が0.4で3連単betすると収益は-8950, 回収率は0.8687683284457478\n",
      "p1が0.8以上かつ、p2が0.6以上かつp3が0.5で3連単betすると収益は-7660, 回収率は0.792972972972973\n",
      "p1が0.8以上かつ、p2が0.6以上かつp3が0.6で3連単betすると収益は-4020, 回収率は0.7766666666666666\n",
      "p1が0.8以上かつ、p2が0.7以上かつp3が0.3で3連単betすると収益は1210, 回収率は1.0414383561643836\n",
      "p1が0.8以上かつ、p2が0.7以上かつp3が0.4で3連単betすると収益は-5620, 回収率は0.6912087912087912\n",
      "p1が0.8以上かつ、p2が0.7以上かつp3が0.5で3連単betすると収益は-1960, 回収率は0.7421052631578947\n",
      "p1が0.8以上かつ、p2が0.7以上かつp3が0.6で3連単betすると収益は-1320, 回収率は0.6333333333333333\n",
      "p1=0.8, p2=0.7, p3=0.7の時、投票候補なし\n",
      "p1が0.8以上かつ、p2が0.8以上かつp3が0.3で3連単betすると収益は410, 回収率は1.292857142857143\n",
      "p1が0.8以上かつ、p2が0.8以上かつp3が0.4で3連単betすると収益は1010, 回収率は2.2625\n",
      "p1が0.8以上かつ、p2が0.8以上かつp3が0.5で3連単betすると収益は310, 回収率は1.5166666666666666\n",
      "p1が0.8以上かつ、p2が0.8以上かつp3が0.6で3連単betすると収益は-400, 回収率は0.0\n",
      "p1=0.8, p2=0.8, p3=0.7の時、投票候補なし\n",
      "p1=0.8, p2=0.8, p3=0.8の時、投票候補なし\n"
     ]
    }
   ],
   "source": [
    "# 1号艇の勝率x_1以上の時、他の艇で3位以内率x_2以上が1艇, X_3以上が1艇以上あった場合に、1頭で、x_2以上艇を2, 3着boxにして買う\n",
    "# ただし、2-6号艇のうち二つ以上の艇がx_２を超えていた場合、それらに対しては2倍のbet額になるアルゴリズムになっている\n",
    "x_1_list = [0.6, 0.7, 0.75, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "x_3_list = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        for x_3 in x_3_list:\n",
    "            if x_3 <= x_2:\n",
    "\n",
    "                income = 0\n",
    "                bet = 0\n",
    "\n",
    "                for index, row in for_calc_refund_rate_df.iterrows():\n",
    "                    if (row[\"PredProb_1\"] > x_1):\n",
    "                        for j in range(2, 7):\n",
    "                            if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                                for k in range(2, 7):\n",
    "                                    if k is not j and row[\"PredProb_{0}\".format(k)] > x_3:\n",
    "                                        bet = bet + 200\n",
    "                                        bet_num_1 = \"1-{0}-{1}\".format(j, k)\n",
    "                                        bet_num_2 = \"1-{0}-{1}\".format(k, j)\n",
    "\n",
    "                                        if row[\"trifecta\"] == bet_num_1 or row[\"trifecta\"] == bet_num_2:\n",
    "                                            income = income + row[\"trifectaOdds\"]\n",
    "                                        # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "                try:\n",
    "                    text = \"p1が{0}以上かつ、p2が{1}以上かつp3が{2}で3連単betすると収益は{3}, 回収率は{4}\".format(x_1, x_2, x_3, income-bet, income/bet)\n",
    "                    if (income / bet) < 1:\n",
    "                        text = termcolor.colored(text, \"red\")\n",
    "                    print(text)\n",
    "                except ZeroDivisionError:\n",
    "                    print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1号艇の勝率x_1以上,2号艇の勝率x_2以上のとき、2-1にbet\n",
    "x_1_list = [0.3, 0.6, 0.7, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        income = 0\n",
    "        bet = 0\n",
    "\n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                if row[\"PredProb_2\".format(j)] > x_2:\n",
    "                    bet = bet + 100\n",
    "\n",
    "                    if row[\"exacta\"] == \"2-1\":\n",
    "                        income = income + row[\"exactaOdds\"]\n",
    "                    # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "        try:\n",
    "            text = \"p1が{0}以上かつ、p2が{1}以上で2連単2-1にbetすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet)\n",
    "            if (income / bet) < 1:\n",
    "                text = termcolor.colored(text, \"red\")\n",
    "            print(text)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_list = [0.6, 0.7, 0.75, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "x_3_list = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        for x_3 in x_3_list:\n",
    "            if x_3 <= x_2:\n",
    "\n",
    "                income = 0\n",
    "                bet = 0\n",
    "\n",
    "                for index, row in for_calc_refund_rate_df.iterrows():\n",
    "                    if (row[\"PredProb_1\"] > x_1):\n",
    "                        for j in range(2, 7):\n",
    "                            if row[\"PredProb_{0}\".format(j)] > x_2:\n",
    "                                for k in range(2, 7):\n",
    "                                    if k is not j and row[\"PredProb_{0}\".format(k)] > x_3:\n",
    "                                        bet = bet + 200\n",
    "                                        bet_num_1 = \"1-{0}-{1}\".format(j, k)\n",
    "                                        bet_num_2 = \"1-{0}-{1}\".format(k, j)\n",
    "\n",
    "                                        if row[\"trifecta\"] == bet_num_1 or row[\"trifecta\"] == bet_num_2:\n",
    "                                            income = income + row[\"trifectaOdds\"]\n",
    "                                        # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "                try:\n",
    "                    text = \"p1が{0}以上かつ、p2が{1}以上かつp3が{2}で3連単betすると収益は{3}, 回収率は{4}\".format(x_1, x_2, x_3, income-bet, income/bet)\n",
    "                    if (income / bet) < 1:\n",
    "                        text = termcolor.colored(text, \"red\")\n",
    "                    print(text)\n",
    "                except ZeroDivisionError:\n",
    "                    print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1号艇の勝率x_1以上,3号艇の勝率x_2以上のとき、3-1にbet\n",
    "x_1_list = [0.3, 0.6, 0.7, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        income = 0\n",
    "        bet = 0\n",
    "\n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                if row[\"PredProb_3\".format(j)] > x_2:\n",
    "                    bet = bet + 100\n",
    "\n",
    "                    if row[\"exacta\"] == \"3-1\":\n",
    "                        income = income + row[\"exactaOdds\"]\n",
    "                    # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "        try:\n",
    "            text = \"p1が{0}以上かつ、p2が{1}以上で2連単2-1にbetすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet)\n",
    "            if (income / bet) < 1:\n",
    "                text = termcolor.colored(text, \"red\")\n",
    "            print(text)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1号艇の勝率x_1以上,4号艇の勝率x_2以上のとき、4-1にbet\n",
    "x_1_list = [0.3, 0.6, 0.7, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        income = 0\n",
    "        bet = 0\n",
    "\n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                if row[\"PredProb_4\".format(j)] > x_2:\n",
    "                    bet = bet + 100\n",
    "\n",
    "                    if row[\"exacta\"] == \"4-1\":\n",
    "                        income = income + row[\"exactaOdds\"]\n",
    "                    # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "        try:\n",
    "            text = \"p1が{0}以上かつ、p2が{1}以上で2連単2-1にbetすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet)\n",
    "            if (income / bet) < 1:\n",
    "                text = termcolor.colored(text, \"red\")\n",
    "            print(text)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1号艇の勝率x_1以上,2号艇の勝率x_2以上のとき、1-2にbet\n",
    "x_1_list = [0.3, 0.6, 0.7, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        income = 0\n",
    "        bet = 0\n",
    "\n",
    "        for index, row in for_calc_refund_rate_df.iterrows():\n",
    "            if (row[\"PredProb_1\"] > x_1):\n",
    "                if row[\"PredProb_2\".format(j)] > x_2:\n",
    "                    bet = bet + 100\n",
    "\n",
    "                    if row[\"exacta\"] == \"1-2\":\n",
    "                        income = income + row[\"exactaOdds\"]\n",
    "                    # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "        try:\n",
    "            text = \"p1が{0}以上かつ、p2が{1}以上で2連単2-1にbetすると収益は{2}, 回収率は{3}\".format(x_1, x_2, income-bet, income/bet)\n",
    "            if (income / bet) < 1:\n",
    "                text = termcolor.colored(text, \"red\")\n",
    "            print(text)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1号艇の勝率x_1以上,2号艇の勝率x_2以上のときで、x_3を超えている他の艇に対して2-1-XXにbet\n",
    "x_1_list = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "x_2_list = [0.6, 0.7, 0.8]\n",
    "x_3_list = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "for x_1 in x_1_list:\n",
    "    for x_2 in x_2_list:\n",
    "        for x_3 in x_3_list:\n",
    "            income = 0\n",
    "            bet = 0\n",
    "\n",
    "            for index, row in for_calc_refund_rate_df.iterrows():\n",
    "                if (row[\"PredProb_1\"] > x_1):\n",
    "                    if row[\"PredProb_2\".format(j)] > x_2:\n",
    "                        for i in range(3, 7):\n",
    "                            if row[\"PredProb_{0}\".format(i)] > x_3:\n",
    "                                bet = bet + 100\n",
    "\n",
    "                                if row[\"trifecta\"] == \"2-1-{0}\".format(i):\n",
    "                                    income = income + row[\"trifectaOdds\"]\n",
    "                                # print(bet_num, row[\"trifecta\"], row[\"trifectaOdds\"], bet, income)\n",
    "            try:\n",
    "                text = \"p1 > {0}、p2 > {1}, p3 > {2}で3連単2-1-i にbetすると収益は{3}, 回収率は{4}\".format(x_1, x_2, x_3, income-bet, income/bet)\n",
    "                if (income / bet) < 1:\n",
    "                    text = termcolor.colored(text, \"red\")\n",
    "                print(text)\n",
    "            except ZeroDivisionError:\n",
    "                print(\"p1={0}, p2={1}, p3={2}の時、投票候補なし\".format(x_1, x_2, x_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_2 > 0.8 さえ入れればほとんどのx_1, x_3でプラスになるぞおおおおおお\n",
    "### x_1 > 0.4, x_2 > 0.8, x_3 > 0.6を満たすレースへbetしていってみる探す"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
